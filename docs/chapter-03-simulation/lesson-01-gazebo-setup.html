<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-chapter-03-simulation/lesson-01-gazebo-setup" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Gazebo Simulation Environment Setup | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://NaimalArain13.github.io/physical-ai-and-humaniod-robotics/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://NaimalArain13.github.io/physical-ai-and-humaniod-robotics/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://NaimalArain13.github.io/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-01-gazebo-setup"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="ur"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Gazebo Simulation Environment Setup | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Setting up Gazebo for physics simulation and understanding robot description formats"><meta data-rh="true" property="og:description" content="Setting up Gazebo for physics simulation and understanding robot description formats"><link data-rh="true" rel="icon" href="/physical-ai-and-humaniod-robotics/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://NaimalArain13.github.io/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-01-gazebo-setup"><link data-rh="true" rel="alternate" href="https://NaimalArain13.github.io/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-01-gazebo-setup" hreflang="en"><link data-rh="true" rel="alternate" href="https://NaimalArain13.github.io/physical-ai-and-humaniod-robotics/ur/docs/chapter-03-simulation/lesson-01-gazebo-setup" hreflang="ur"><link data-rh="true" rel="alternate" href="https://NaimalArain13.github.io/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-01-gazebo-setup" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Gazebo Simulation Environment Setup","item":"https://NaimalArain13.github.io/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-01-gazebo-setup"}]}</script><link rel="alternate" type="application/rss+xml" href="/physical-ai-and-humaniod-robotics/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/physical-ai-and-humaniod-robotics/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Atom Feed"><link rel="stylesheet" href="/physical-ai-and-humaniod-robotics/assets/css/styles.dbe2c117.css">
<script src="/physical-ai-and-humaniod-robotics/assets/js/runtime~main.ee32089f.js" defer="defer"></script>
<script src="/physical-ai-and-humaniod-robotics/assets/js/main.5011750a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/physical-ai-and-humaniod-robotics/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/physical-ai-and-humaniod-robotics/"><div class="navbar__logo"><img src="/physical-ai-and-humaniod-robotics/img/logo.svg" alt="Physical AI &amp; Robotics Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/physical-ai-and-humaniod-robotics/img/logo.svg" alt="Physical AI &amp; Robotics Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/physical-ai-and-humaniod-robotics/docs/overview">Tutorial</a><a class="navbar__item navbar__link" href="/physical-ai-and-humaniod-robotics/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/NaimalArain13/physical-ai-and-humaniod-robotics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-01-gazebo-setup" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/physical-ai-and-humaniod-robotics/ur/docs/chapter-03-simulation/lesson-01-gazebo-setup" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ur">ÿßÿ±ÿØŸà</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/physical-ai-and-humaniod-robotics/docs/overview"><span title="Course Overview" class="linkLabel_WmDU">Course Overview</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-and-humaniod-robotics/docs/chapter-01-foundations/lesson-01-intro-embodied-intelligence"><span title="Chapter 1: Foundations" class="categoryLinkLabel_W154">Chapter 1: Foundations</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-and-humaniod-robotics/docs/chapter-02-ros2/lesson-01-ros2-architecture"><span title="Chapter 2: ROS 2 Fundamentals" class="categoryLinkLabel_W154">Chapter 2: ROS 2 Fundamentals</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-01-gazebo-setup"><span title="Chapter 3: Simulation" class="categoryLinkLabel_W154">Chapter 3: Simulation</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-01-gazebo-setup"><span title="Gazebo Simulation Environment Setup" class="linkLabel_WmDU">Gazebo Simulation Environment Setup</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-02-urdf-sdf-formats"><span title="URDF and SDF Formats" class="linkLabel_WmDU">URDF and SDF Formats</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/physical-ai-and-humaniod-robotics/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Chapter 3: Simulation</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Gazebo Simulation Environment Setup</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Gazebo Simulation Environment Setup</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">‚Äã</a></h2>
<p>Breaking a $100,000 humanoid robot because your balance controller had a bug is expensive. Crashing a virtual robot in Gazebo and restarting in 5 seconds is free. This fundamental asymmetry is why simulation has become the first deployment target for every robotics algorithm‚Äîfrom academic research to commercial products.</p>
<p>Hardware development is inherently slow (fabrication takes weeks), expensive (sensor suites cost thousands), and fragile (one bad command can cause mechanical damage). Simulation flips these constraints: iterate on algorithms in minutes, test dangerous scenarios safely, and reproduce experiments with perfect consistency. When NASA tests Valkyrie&#x27;s manipulation tasks for the International Space Station, they simulate thousands of scenarios in Gazebo before touching the real robot. When Unitree develops walking controllers for their bipedal humanoids, they spend 90% of development time in simulation.</p>
<p>The evolution from Gazebo Classic (2012-2022) to modern Gazebo (formerly called Ignition, 2019-present) reflects robotics&#x27; growing sophistication‚Äîbetter physics engines for contact dynamics, photorealistic rendering for vision algorithms, and seamless ROS 2 integration. For humanoid robotics specifically, Gazebo excels at simulating the complex foot-ground contact forces that make bipedal locomotion so challenging.</p>
<p>This lesson introduces you to Gazebo as the bridge between theoretical algorithms and physical hardware‚Äîwhere you develop, test, and validate before deploying to reality.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Direct link to Learning Objectives" title="Direct link to Learning Objectives" translate="no">‚Äã</a></h2>
<p>By the end of this lesson, you will be able to:</p>
<ul>
<li class="">Set up a Gazebo simulation environment integrated with ROS 2 for robot development</li>
<li class="">Understand SDF and URDF formats for defining robot models, including geometry, kinematics, and dynamics</li>
<li class="">Configure sensor plugins (camera, LiDAR, IMU) with realistic noise models to simulate perception systems</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-concepts">Key Concepts<a href="#key-concepts" class="hash-link" aria-label="Direct link to Key Concepts" title="Direct link to Key Concepts" translate="no">‚Äã</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="physics-engines-and-simulation-fidelity">Physics Engines and Simulation Fidelity<a href="#physics-engines-and-simulation-fidelity" class="hash-link" aria-label="Direct link to Physics Engines and Simulation Fidelity" title="Direct link to Physics Engines and Simulation Fidelity" translate="no">‚Äã</a></h3>
<p>Gazebo doesn&#x27;t compute physics itself‚Äîit delegates to specialized physics engines that solve the differential equations governing rigid body dynamics. You can choose between ODE (Open Dynamics Engine, fast but less accurate), Bullet (balanced performance), and DART (Dynamic Animation and Robotics Toolkit, slow but highly accurate for complex contacts). Each makes different trade-offs between computational speed and physical realism.</p>
<p>What does a physics engine simulate? Rigid body dynamics (how forces cause acceleration), collision detection (when two objects intersect), contact forces (the reaction forces when colliding objects touch), and joint constraints (keeping linked bodies together). The real-time factor measures simulation speed: 1.0 means simulation runs at real-world speed, 2.0 means twice as fast, 0.5 means half-speed (common for complex humanoids).</p>
<p>Tuning simulation parameters is critical for behavior transfer. Consider simulating Unitree&#x27;s H1 humanoid walking: if foot-floor friction is too low, the robot slips unrealistically; too high, and foot scuffing causes instability. You must tune contact parameters (friction coefficients, contact stiffness) and time step size (smaller = more accurate but slower) to match real-world behavior. Getting this right is the difference between controllers that work in sim but fail on hardware versus those that transfer successfully.</p>
<blockquote>
<p>üí° <strong>The Sim-to-Real Gap</strong>: Simulation is never perfect. Good simulations achieve 70-90% behavior transfer to real hardware‚Äîmeaning controllers developed entirely in simulation work reasonably well on real robots after minor tuning. Closing the remaining gap requires techniques like domain randomization (varying physics parameters during training) and system identification (measuring real robot properties to match simulation).</p>
</blockquote>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="sdfurdf-robot-description-formats">SDF/URDF Robot Description Formats<a href="#sdfurdf-robot-description-formats" class="hash-link" aria-label="Direct link to SDF/URDF Robot Description Formats" title="Direct link to SDF/URDF Robot Description Formats" translate="no">‚Äã</a></h3>
<p>Robots in Gazebo are defined using XML files that specify everything from geometry to mass distribution. ROS uses URDF (Unified Robot Description Format), which defines robots as trees of links (rigid bodies) connected by joints. Gazebo natively uses SDF (Simulation Description Format), which is a superset of URDF‚Äîit can describe not just robots but entire worlds, including lighting, physics parameters, and sensor configurations.</p>
<p>A robot&#x27;s structure consists of links and joints. Links are rigid bodies with properties like mass, center-of-mass offset, and inertia tensors (how mass is distributed). Each link has two representations: visual geometry (detailed meshes for rendering, can be high-polygon) and collision geometry (simplified shapes for physics computation, should be low-complexity). Joints connect links and define degrees of freedom‚Äîrevolute joints (1D rotation, like elbows), prismatic joints (1D linear motion, like telescoping), or fixed joints (rigidly connected).</p>
<p>Example: defining a humanoid robot&#x27;s torso. The link element specifies mass (10 kg), inertia matrix (resistance to rotation), a detailed mesh for visualization (<code>torso.dae</code>), and a simplified cylinder for collision detection. Attaching leg joints to this torso link creates the kinematic tree. The key insight: separating visual and collision geometry dramatically improves simulation performance while maintaining realistic appearance.</p>
<blockquote>
<p>‚ö†Ô∏è <strong>Common Mistake</strong>: Using high-polygon visual meshes (100K+ triangles) for collision geometry causes simulation to crawl at less than 0.1x real-time. Always use simplified collision shapes‚Äîboxes, cylinders, convex hulls with fewer than 1000 triangles. The simulation only &quot;sees&quot; collision geometry for physics; visual geometry is just for rendering.</p>
</blockquote>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="sensor-simulation-and-noise-models">Sensor Simulation and Noise Models<a href="#sensor-simulation-and-noise-models" class="hash-link" aria-label="Direct link to Sensor Simulation and Noise Models" title="Direct link to Sensor Simulation and Noise Models" translate="no">‚Äã</a></h3>
<p>Gazebo simulates the sensors that robots use to perceive their environment. Camera sensors produce RGB images, depth maps (distance to every pixel), and semantic segmentation (if using specialized plugins). LiDAR sensors generate 2D laser scans (think Hokuyo sweeping in a plane) or 3D point clouds (Velodyne-style spinning lasers). IMU sensors provide linear acceleration and angular velocity‚Äîabsolutely essential for humanoid balance control, which relies on detecting tilting in real-time.</p>
<p>Critically, simulated sensors include noise models. Real sensors don&#x27;t provide perfect data‚Äîcamera images have noise, LiDAR has range uncertainty, IMUs drift over time. Gazebo lets you configure Gaussian noise parameters (mean, standard deviation) for each sensor to match real-world characteristics. This prevents the common pitfall of developing perception algorithms on perfect simulated data that fail when deployed to noisy real sensors.</p>
<p>ROS 2 integration happens through the <code>ros_gz_bridge</code>‚Äîa translator that publishes simulated sensor data to standard ROS 2 topics. To your perception algorithms, simulated camera data on <code>/camera/image_raw</code> looks identical to data from a real RealSense camera. This enables seamless sim-to-real transfer: develop your object detector on simulated images, then deploy to real hardware by simply changing the launch file (no code modifications).</p>
<blockquote>
<p>üìä <strong>Sensor Data Flow</strong>: Gazebo sensor plugin generates data ‚Üí <code>ros_gz_bridge</code> translates to ROS 2 message ‚Üí Published to topic (e.g., <code>/scan</code>, <code>/camera/image_raw</code>) ‚Üí Your perception node subscribes and processes. The perception node doesn&#x27;t know if data comes from simulation or real hardware‚Äîthis abstraction is powerful.</p>
</blockquote>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="hands-on-exercise">Hands-on Exercise<a href="#hands-on-exercise" class="hash-link" aria-label="Direct link to Hands-on Exercise" title="Direct link to Hands-on Exercise" translate="no">‚Äã</a></h2>
<p><strong>Prerequisites:</strong></p>
<ul>
<li class="">Ubuntu 22.04 (or Ubuntu 20.04 with modifications)</li>
<li class="">ROS 2 Humble installed (or Foxy for Ubuntu 20.04)</li>
<li class="">Gazebo installed: <code>sudo apt install ros-humble-ros-gz</code></li>
<li class="">Completion of Lesson 2.1 (ROS 2 fundamentals)</li>
</ul>
<p><strong>Activity: Launch Gazebo and Inspect Sensor Data</strong></p>
<ol>
<li class=""><strong>Launch example simulation world</strong>:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Source ROS 2 environment</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source /opt/ros/humble/setup.bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Launch a Gazebo world with a robot (using demo package)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ros2 launch ros_gz_sim empty_world.launch.py</span><br></span></code></pre></div></div>
<p>The Gazebo GUI should launch, showing an empty world. You can insert models from the left panel.</p>
<ol start="2">
<li class=""><strong>Insert a robot with sensors</strong>:</li>
</ol>
<ul>
<li class="">In Gazebo GUI, go to the Insert tab</li>
<li class="">Find &quot;Simple Robot with Camera&quot; or similar model</li>
<li class="">Click to place in the world</li>
</ul>
<ol start="3">
<li class=""><strong>Inspect ROS 2 topics from simulation</strong>:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Open new terminal, list active topics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ros2 topic list</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># You should see simulated sensor topics like:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># /camera/image_raw</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># /camera/depth/image_raw</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># /scan (if robot has LiDAR)</span><br></span></code></pre></div></div>
<ol start="4">
<li class=""><strong>Visualize camera data</strong>:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Install image viewer if needed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo apt install ros-humble-rqt-image-view</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Launch image viewer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ros2 run rqt_image_view rqt_image_view</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Select /camera/image_raw from dropdown</span><br></span></code></pre></div></div>
<ol start="5">
<li class=""><strong>Echo LiDAR data (if available)</strong>:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ros2 topic echo /scan --once</span><br></span></code></pre></div></div>
<p>You&#x27;ll see a <code>LaserScan</code> message with arrays of range measurements‚Äîsame format as real LiDAR!</p>
<ol start="6">
<li class=""><strong>Inspect robot description</strong>:</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># View the robot&#x27;s URDF/SDF definition</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ros2 topic echo /robot_description --once</span><br></span></code></pre></div></div>
<p>This prints the XML defining the robot&#x27;s structure.</p>
<p><strong>Expected Outcome:</strong></p>
<p>You should see Gazebo simulating a robot with sensors, publishing data to ROS 2 topics using the exact same message types as real hardware. This demonstrates the key principle: perception and control algorithms can be developed on simulated data, then deployed to real robots by changing only the launch file‚Äîno code changes required. The interface (ROS 2 topics) remains identical.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="quiz">Quiz<a href="#quiz" class="hash-link" aria-label="Direct link to Quiz" title="Direct link to Quiz" translate="no">‚Äã</a></h2>
<p>Test your understanding of this lesson:</p>
<ol>
<li class="">
<p>What is the primary benefit of using Gazebo for humanoid robot development?</p>
<ul>
<li class="">A) Gazebo simulations run 10x faster than real-time</li>
<li class="">B) Test dangerous behaviors safely and iterate quickly before deploying to expensive hardware</li>
<li class="">C) Gazebo has better graphics than reality</li>
<li class="">D) ROS 2 requires using Gazebo</li>
</ul>
</li>
<li class="">
<p>Which file format is used to define a robot&#x27;s physical structure in Gazebo?</p>
<ul>
<li class="">A) JSON configuration file</li>
<li class="">B) Python script defining classes</li>
<li class="">C) SDF or URDF XML file specifying links, joints, and sensors</li>
<li class="">D) Binary robot model file</li>
</ul>
</li>
<li class="">
<p>Why must visual and collision geometries be different for robot models?</p>
<ul>
<li class="">A) Visual geometry is for humans to see; collision geometry is for physics calculation and must be simplified for performance</li>
<li class="">B) Visual geometry is required by ROS; collision geometry is required by Gazebo</li>
<li class="">C) They must actually be identical</li>
<li class="">D) Collision geometry is only used during robot crashes</li>
</ul>
</li>
</ol>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Show Answers</summary><div><div class="collapsibleContent_i85q"><ol>
<li class="">
<p><strong>B</strong> - Test dangerous behaviors safely and iterate quickly before deploying to expensive hardware. Simulation lets you crash robots, test edge cases, and try thousands of scenarios without risking physical damage or waiting for hardware fabrication. While speed and graphics are factors, the primary value is safe, rapid iteration.</p>
</li>
<li class="">
<p><strong>C</strong> - SDF or URDF XML file specifying links, joints, and sensors. URDF (Unified Robot Description Format) is the ROS standard; SDF (Simulation Description Format) is Gazebo&#x27;s native format and a superset of URDF. Both are XML files that declaratively define robot structure‚Äîthe geometry, kinematics (how parts move), dynamics (mass, inertia), and attached sensors.</p>
</li>
<li class="">
<p><strong>A</strong> - Visual geometry is for humans to see; collision geometry is for physics calculation and must be simplified for performance. Visual meshes can be highly detailed (100K+ triangles) for realistic rendering. Collision meshes must be simple (preferably primitives like boxes/cylinders, or fewer than 1000 triangle convex hulls) because the physics engine evaluates them every simulation step. Using complex visual meshes for collision causes simulation to become unbearably slow.</p>
</li>
</ol></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-takeaways">Key Takeaways<a href="#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways" translate="no">‚Äã</a></h2>
<ul>
<li class=""><strong>Simulation enables safe, rapid iteration</strong>: Develop and test algorithms in Gazebo before deploying to expensive humanoid hardware, reducing risk and development time by an order of magnitude.</li>
<li class=""><strong>Physics engines trade accuracy for speed</strong>: Choose ODE for fast prototyping, Bullet for balanced performance, or DART for high-fidelity contact dynamics. Tune parameters to match real-world behavior and minimize the sim-to-real gap.</li>
<li class=""><strong>Robot descriptions separate visual and collision geometry</strong>: Detailed meshes for rendering, simplified shapes for physics. This separation is critical for performance‚Äîsimulations with improper collision geometry can run 100x slower.</li>
<li class=""><strong>Simulated sensors use the same ROS 2 interface as real hardware</strong>: The <code>ros_gz_bridge</code> publishes sensor data to standard topics, allowing perception and control code to work unchanged between simulation and reality. This abstraction accelerates development and enables reproducible research.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="further-reading">Further Reading<a href="#further-reading" class="hash-link" aria-label="Direct link to Further Reading" title="Direct link to Further Reading" translate="no">‚Äã</a></h2>
<ul>
<li class=""><a href="https://gazebosim.org/docs" target="_blank" rel="noopener noreferrer" class="">Gazebo Official Documentation</a> - Complete installation guides, tutorials, and API reference for modern Gazebo</li>
<li class=""><a href="https://docs.ros.org/en/humble/Tutorials/Advanced/Simulators/Gazebo/Gazebo.html" target="_blank" rel="noopener noreferrer" class="">ROS 2 + Gazebo Integration Tutorial</a> - Official ROS documentation on ros_gz_bridge and simulation workflows</li>
<li class=""><a href="http://sdformat.org/" target="_blank" rel="noopener noreferrer" class="">SDF Format Specification</a> - Complete XML schema for robot and world descriptions</li>
<li class=""><a href="https://gazebosim.org/docs/latest/building_robot/" target="_blank" rel="noopener noreferrer" class="">Gazebo Building a Robot Tutorial</a> - Step-by-step guide to creating custom robot models with sensors</li>
</ul>
<hr>
<p><strong>Next Lesson</strong>: <a class="" href="/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-02-urdf-sdf-formats">URDF and SDF Formats</a></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/NaimalArain13/physical-ai-and-humaniod-robotics/tree/master/docs/docs/chapter-03-simulation/lesson-01-gazebo-setup.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/physical-ai-and-humaniod-robotics/docs/chapter-02-ros2/lesson-02-nodes-topics-services"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Nodes, Topics, and Services</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/physical-ai-and-humaniod-robotics/docs/chapter-03-simulation/lesson-02-urdf-sdf-formats"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">URDF and SDF Formats</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#key-concepts" class="table-of-contents__link toc-highlight">Key Concepts</a><ul><li><a href="#physics-engines-and-simulation-fidelity" class="table-of-contents__link toc-highlight">Physics Engines and Simulation Fidelity</a></li><li><a href="#sdfurdf-robot-description-formats" class="table-of-contents__link toc-highlight">SDF/URDF Robot Description Formats</a></li><li><a href="#sensor-simulation-and-noise-models" class="table-of-contents__link toc-highlight">Sensor Simulation and Noise Models</a></li></ul></li><li><a href="#hands-on-exercise" class="table-of-contents__link toc-highlight">Hands-on Exercise</a></li><li><a href="#quiz" class="table-of-contents__link toc-highlight">Quiz</a></li><li><a href="#key-takeaways" class="table-of-contents__link toc-highlight">Key Takeaways</a></li><li><a href="#further-reading" class="table-of-contents__link toc-highlight">Further Reading</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-and-humaniod-robotics/docs/intro">Tutorial</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-and-humaniod-robotics/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/NaimalArain13/physical-ai-and-humaniod-robotics" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2025 Physical AI & Humanoid Robotics Textbook. Built with Docusaurus.</div></div></div></footer><button class="chatButton_gSQt" aria-label="Toggle chat" type="button">üí¨</button></div>
</body>
</html>